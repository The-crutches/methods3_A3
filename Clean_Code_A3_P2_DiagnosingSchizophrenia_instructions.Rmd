---
title: "Assignment 3 - Part 2 - Diagnosing Schizophrenia from Voice"
author: "Riccardo Fusaroli"
date: "October 17, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 - Part 2 - Diagnosing schizophrenia from voice

In the previous part of the assignment you generated a bunch of "features", that is, of quantitative descriptors of voice in schizophrenia. We then looked at whether we could replicate results from the previous literature.
We now want to know whether we can automatically diagnose schizophrenia from voice only, that is, relying on the set of features you produced last time, we will try to produce an automated classifier.
Again, remember that the dataset containst 7 studies and 3 languages. Feel free to only include Danish (Study 1-4) if you feel that adds too much complexity.

Issues to be discussed your report:
- Should you run the analysis on all languages/studies at the same time? 
- Choose your best acoustic feature from part 1. How well can you diagnose schizophrenia just using it?
- Identify the best combination of acoustic features to diagnose schizophrenia using logistic regression.
- Discuss the "classification" process: which methods are you using? Which confounds should you be aware of? What are the strength and limitation of the analysis?
- Bonus question: Logistic regression is only one of many classification algorithms. Try using others and compare performance. Some examples: Discriminant Function, Random Forest, Support Vector Machine, etc. The package caret provides them. 
- Bonus Bonus question: It is possible combine the output of multiple  classification models to improve classification accuracy. For inspiration see,
https://machinelearningmastery.com/machine-learning-ensembles-with-r/
 The interested reader might also want to look up 'The BigChaos Solution to the Netflix Grand Prize'

## Learning objectives
- Learn the basics of classification in a machine learning framework
- Design, fit and report logistic regressions
- Apply feature selection techniques

### Let's start

```{r}
#Loading packages
library(pacman)
p_load(tidyverse, tidymodels, lme4, boot, caret, ranger, broom.mixed, groupdata2, cvms)

#Reading data 
df <- read_csv('SchizophreniaData.csv')

#Cleaning data 
df <- df %>% mutate(Diagnosis = factor(Diagnosis),
                    Study = factor(Study),
                    Subject = factor(Subject),
                    Trial = factor(Trial),
                    ID = factor(ID),
                    Gender = factor(Gender),
                    Age = factor(Age), 
                    speechrate = speechrate..nsyll.dur.
                    ) %>% 
  #Removing language, time and f0 because we dont use them 
  select(- Language, - time, - f0) %>%
  select(!starts_with("time")) %>% 
  #Organizing the dataframe
  select(ID, ID2, Subject, Study, Trial, Gender, Age, everything())

#Making the pause duration column and proportion of spoken time column
df <- df %>% mutate(prop_spoken_time = phonationtime..s. / dur..s.,
                    pause_duration = (dur..s. - phonationtime..s.) / npause,)

#Cleaning the pause duration column
df$pause_duration <-  ifelse(df$npause == 0, 0, df$pause_duration)

#Making a new column for diagnosis if it is needed in some of the analysis 
df$Diagnosis1 <-  ifelse(df$Diagnosis == 'Control', 0, 1) %>% as.factor()

```

We first want to build a logistic regression to see whether you can diagnose schizophrenia from your best acoustic feature. Let's use the full dataset and calculate the different performance measures (accuracy, sensitivity, specificity, PPV, NPV, ROC curve). You need to think carefully as to how we should (or not) use study and subject ID.

```{r}
#Building logistic regression 
  #Using speech rate as predictor because it is our best feature from part 1 
m1 <- glmer(Diagnosis1 ~ speechrate + (1|ID), family = 'binomial', df)
summary(m1)

#How well can you diagnose schizophrenia just using it?

#Creating predicted column 
pred_probs <- predict(m1, type = 'response', re.form = NA)

#Actual values
actual_value <- df$Diagnosis

#Creating tible
d <- tibble(pred_probs, actual_value)

#Making the predicted either Schizophrenia or Control
d$pred_category <- ifelse(d$pred_probs > 0.5, 'Schizophrenia', 'Control') %>%  as.factor()

#Then confusion matrix 
confusionMatrix(d$pred_category, d$actual_value, positive = 'Schizophrenia')
  #It is very bad
```

```{r}
#Partitioning 
p1 <- partition(df, p = 0.2, cat_col = 'Diagnosis1', id_col = 'ID')
  #Making test set 
df_test <- p1[[1]]
  #Making train set 
df_train <- p1[[2]]

#Scaling data 
df_train <- df_train %>% mutate_if(is.numeric, scale)
df_train <- df_train %>% select(ID, Diagnosis1, speechrate, pause_duration, pitch_IQR, prop_spoken_time)

#looking at correlations
a <-cor(df_train %>% 
          select_if(is.numeric))
  #Making correlations as matrix
a <- as.data.frame(a)
  #Speechrate and prop of spoken time = correlated
```

```{r}
#Identify the best combination of acoustic features to diagnose schizophrenia using logistic regression

# speechrate and proportion of spoken time are highly correlated so we choose to remove proportion of spoken time

f0 <- glmer(Diagnosis1 ~ speechrate + pause_duration + pitch_IQR + (1|ID), family = 'binomial', df_train)
f1 <- glmer(Diagnosis1 ~ speechrate + pause_duration + (1|ID), family = 'binomial', df_train)
f2 <- glmer(Diagnosis1 ~ speechrate + pitch_IQR + (1|ID), family = 'binomial', df_train)
f3 <- glmer(Diagnosis1 ~ pause_duration + pitch_IQR + (1|ID), family = 'binomial', df_train)

anova(f0, f1, f2, f3)

# f2 is the best model when comparing AIC and BIC
```


we're using the packages groupdata2 and cvms in order to crossvalidate our model. for this we are trying to use support vector machines. we are also tuning the parameters in order to find the best combination of kernel and cost.

```{r}
#from cvms 

clf_svm_model_fn <- function(train_data, formula, hyperparameters) {

  # Optional hyperparameters:
  #  - kernel
  #  - cost

  # Update missing hyperparameters with default values
  hyperparameters <- update_hyperparameters(
    kernel = "radial",
    cost = 1,
    hyperparameters = hyperparameters
  )

  e1071::svm(
    formula = formula,
    data = train_data,
    kernel = hyperparameters[["kernel"]],
    cost = hyperparameters[["cost"]],
    type = "C-classification",
    probability = TRUE  # Must enable probability here
  )
}

```


```{r}
df_test <- df_test %>% mutate_if(is.numeric, scale)
# Predict function for binomial SVM
bnml_svm_predict_fn <- function(test_data, model, formula, hyperparameters, train_data) {
  # Predict test set
  predictions <- predict(
    object = model,
    newdata = test_data,
    allow.new.levels = TRUE,
    probability = TRUE
  )
  
  # Extract probabilities
  probabilities <- dplyr::as_tibble(attr(predictions, "probabilities"))
  
  # Return second column
  probabilities[[2]]
}

```

```{r}
#create folds in training data
set.seed(5)
df_train <- fold(df_train, 
                 k = 10, 
                 cat_col = 'Diagnosis1', 
                 id_col = 'ID', 
                 num_fold_cols = 10)

#now we can cross validate 
doParallel::registerDoParallel()
cv_4 <- cross_validate_fn(
  data = df_train,
  formulas = c("Diagnosis1 ~ speechrate + pitch_IQR"),
  type = "binomial",
  model_fn = clf_svm_model_fn,
  predict_fn = bnml_svm_predict_fn,
  hyperparameters = list(
    "kernel" = c("linear", "radial"),
    "cost" = c(1, 5, 10)
  ),
  fold_cols = paste0(".folds_", 1:10)
)

# creating 600 models, takes time
```

assesing the results to find the best combination:

```{r}
cv_4 %>% 
  mutate(`Model ID` = 1:nrow(cv_4)) %>% 
  arrange(desc(`Balanced Accuracy`)) %>% 
  select_definitions(additional_includes = c("Balanced Accuracy", "F1", "MCC", "Model ID"))

```

now we want to fit our test data with the best model from our cross validation results.
This model used a linear kernel to fit the support vectors and a cost of 1. 

```{r}
# correcting our test data so that is is also scaled and selecting the appropiate columns
df_test <- df_test %>% select(ID, Diagnosis, Diagnosis1, speechrate, pause_duration, pitch_IQR, prop_spoken_time)

# we run m1 again to have everything here
m1 <- clf_svm_model_fn(train_data = df_train, formula = Diagnosis1 ~ speechrate + pitch_IQR, 
                       hyperparameters = list("kernel" = "linear"))
summary(m1)

# here we get the predictions on our test data, using m1
pred_svm <- bnml_svm_predict_fn(test_data = df_test, model = m1)
# gathering the actual values from the test data
actual_values <- df_test %>% select(Diagnosis)
# binding them to one df
df_final <- cbind(actual_values, pred_svm)

#creating predicted category from the numeric predictions
df_final$pred_cat_svm <- ifelse(df_final$pred_svm > 0.8, 'Schizophrenia', 'Control') %>%  as.factor()

cm_final <- confusionMatrix(df_final$pred_cat_svm, df_final$Diagnosis, positive = 'Schizophrenia')
cm_final


```

now we compare with regular glm for comparison

```{r}
#Cross validation of the the logistic regression from the best feature 

#create the function from package cvms in order to crossvalidate
glm_model_fn <- function(train_data, formula, hyperparameters) {
  glm(formula = formula, data = train_data, family = "binomial")
}

glm_predict_fn <- function(test_data, model, formula,
                           hyperparameters, train_data) {
  stats::predict(
    object = model,
    newdata = test_data,
    type = "response",
    allow.new.levels = TRUE
  )
}

cv_5 <- cross_validate_fn(
  data = df_train,
  formulas = c("Diagnosis1 ~ speechrate + pitch_IQR"),
  type = "binomial",
  model_fn = glm_model_fn,
  predict_fn = glm_predict_fn,
  fold_cols = paste0(".folds_", 1:10)
)


```

```{r}
# regular glm
m3 <- glm_model_fn(train_data = df_train, formula = Diagnosis1 ~ speechrate + pitch_IQR)

# here we get the predictions on our test data, using m3
pred_glm <- glm_predict_fn(test_data = df_test, model = m3)
# gathering the actual values from the test data
actual_values <- df_test %>% select(Diagnosis)
# binding them to one df
df_final_2 <- cbind(actual_values, pred_glm)

#creating predicted category from the numeric predictions
df_final_2$pred_cat_glm <- ifelse(df_final_2$pred_glm > 0.8, 'Schizophrenia', 'Control') %>%  as.factor()

cm_final_2 <- confusionMatrix(df_final_2$pred_cat_glm, df_final_2$Diagnosis, positive = 'Schizophrenia')
cm_final_2


```




